package openai

import (
	"bytes"
	"context"
	"encoding/base64"
	"encoding/json"
	"fmt"
	"io"
	"log"
	"net/http"
	"strings"
	"time"

	"llm-proxy/api/internal/ocr"
	"llm-proxy/api/internal/ocr/types"
	"llm-proxy/api/internal/util"
)

type Engine struct {
	APIKey string
	Model  string
	httpc  *http.Client
}

func New(key, model string) *Engine {
	return &Engine{
		APIKey: key,
		Model:  model,
		httpc:  &http.Client{Timeout: 60 * time.Second},
	}
}

func (e *Engine) Name() string { return "gpt" }

func (e *Engine) GetModel() string { return e.Model }

func (e *Engine) Detect(ctx context.Context, in types.DetectInput) (types.DetectResult, error) {
	if e.APIKey == "" {
		return types.DetectResult{}, fmt.Errorf("OPENAI_API_KEY not set")
	}

	// accept raw base64 or data: URL
	imgBytes, mimeFromDataURL, _ := util.DecodeBase64MaybeDataURL(in.ImageB64)
	if len(imgBytes) == 0 {
		raw, err := base64.StdEncoding.DecodeString(in.ImageB64)
		if err != nil {
			return types.DetectResult{}, fmt.Errorf("openai detect: invalid image base64")
		}
		imgBytes = raw
	}
	mime := util.PickMIME(in.Mime, mimeFromDataURL, imgBytes)
	if !isOpenAIImageMIME(mime) {
		return types.DetectResult{}, fmt.Errorf("openai detect: unsupported MIME %s (need image/jpeg|png|webp)", mime)
	}
	dataURL := "data:" + mime + ";base64," + base64.StdEncoding.EncodeToString(imgBytes)

	system := `DETECT â€” system prompt v5.2 (text-only, PII OFF per MVP)

Ð Ð¾Ð»ÑŒ: Ñ‚Ñ‹ â€” Ð¼Ð¾Ð´ÑƒÐ»ÑŒ DETECT ÑÐµÑ€Ð²Ð¸ÑÐ° Â«ÐžÐ±ÑŠÑÑÐ½ÑÑ‚ÐµÐ»ÑŒ Ð”Ð—Â». Ð•Ð´Ð¸Ð½ÑÑ‚Ð²ÐµÐ½Ð½Ð°Ñ Ð·Ð°Ð´Ð°Ñ‡Ð° â€” Ð¸Ð·Ð²Ð»ÐµÑ‡ÑŒ Ð·Ð°Ð´Ð°Ñ‡Ð¸ Ñ Ñ„Ð¾Ñ‚Ð¾/ÑÐºÐ°Ð½Ð° Ð¸ Ð²ÐµÑ€Ð½ÑƒÑ‚ÑŒ ÐžÐ”Ð˜Ð ÐºÐ¾Ñ€Ð½ÐµÐ²Ð¾Ð¹ Ð¾Ð±ÑŠÐµÐºÑ‚ ÑÑ‚Ñ€Ð¾Ð³Ð¾ Ð² JSON Ð¿Ð¾ detect.schema.json.

âš™ï¸ Ð¤Ð¾Ñ€Ð¼Ð°Ñ‚ Ð¾Ñ‚Ð²ÐµÑ‚Ð°
â€¢ ÐžÑ‚Ð²ÐµÑ‚ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ JSON Ð¿Ð¾ detect.schema.json.
â€¢ ÐÐ¸ÐºÐ°ÐºÐ¸Ñ… Ñ€ÐµÑˆÐµÐ½Ð¸Ð¹, Ð¿Ð¾ÑÑÐ½ÐµÐ½Ð¸Ð¹, Ñ€Ð°ÑÑÑƒÐ¶Ð´ÐµÐ½Ð¸Ð¹, Markdown Ð¸ Ð¿Ñ€ÐµÑ„Ð¸ÐºÑÐ¾Ð².
â€¢ Ð¡Ñ…ÐµÐ¼Ð° Ð¿ÐµÑ€ÐµÐ´Ð°Ñ‘Ñ‚ÑÑ Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ð¾Ð¼ Ð²Ñ‹Ð·Ð¾Ð²Ð° response_format: { type: "json_schema", json_schema: detect.schema.json } â€” Ð½Ðµ Ð²ÑÑ‚Ð°Ð²Ð»ÑÐ¹ ÑÑ…ÐµÐ¼Ñƒ Ð² Ñ‚ÐµÐºÑÑ‚.
â€¢ ÐšÐ¾Ð½ÐµÑ† Ð¾Ñ‚Ð²ÐµÑ‚Ð° â€” Ð·Ð°ÐºÑ€Ñ‹Ð²Ð°ÑŽÑ‰Ð°Ñ Ñ„Ð¸Ð³ÑƒÑ€Ð½Ð°Ñ ÑÐºÐ¾Ð±ÐºÐ° ÐºÐ¾Ñ€Ð½ÐµÐ²Ð¾Ð³Ð¾ Ð¾Ð±ÑŠÐµÐºÑ‚Ð°. Ð›ÑŽÐ±Ð¾Ð¹ Ñ‚ÐµÐºÑÑ‚ Ð²Ð½Ðµ JSON â€” Ð¾ÑˆÐ¸Ð±ÐºÐ°.

ðŸ“ Ð–Ñ‘ÑÑ‚ÐºÐ¸Ðµ Ð¿Ñ€Ð°Ð²Ð¸Ð»Ð°
1) VERBATIM. ÐÐµÐ»ÑŒÐ·Ñ Ð¸Ð·Ð¼ÐµÐ½ÑÑ‚ÑŒ Ð¸ÑÑ…Ð¾Ð´Ð½Ñ‹Ð¹ Ñ‚ÐµÐºÑÑ‚: Ð¿Ð¾Ñ€ÑÐ´Ð¾Ðº ÑÐ»Ð¾Ð², Ñ€ÐµÐ³Ð¸ÑÑ‚Ñ€, Â«Ðµ/Ñ‘Â», Ð¿ÑƒÐ½ÐºÑ‚ÑƒÐ°Ñ†Ð¸ÑŽ, Ñ‚Ð¸Ð¿/ÐºÐ¾Ð»-Ð²Ð¾ Ð¿Ñ€Ð¾Ð±ÐµÐ»Ð¾Ð² (Ð²ÐºÐ»ÑŽÑ‡Ð°Ñ NBSP), Ñ‚Ð°Ð±Ñ‹, Ð¿ÐµÑ€ÐµÐ½Ð¾ÑÑ‹ ÑÑ‚Ñ€Ð¾Ðº.
2) NUMBERS. Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐ¹ Ñ€Ð°Ð·Ñ€ÑÐ´Ð½Ñ‹Ðµ Ð¿Ñ€Ð¾Ð±ÐµÐ»Ñ‹ (Â«68 000Â», Â«3 516 997Â») Ð¸ Ð¸Ñ… Ñ‚Ð¸Ð¿. ÐÐµ ÑÐºÐ»ÐµÐ¸Ð²Ð°Ñ‚ÑŒ Â«68000Â», Ð½Ðµ Ð·Ð°Ð¼ÐµÐ½ÑÑ‚ÑŒ Ð¿Ñ€Ð¾Ð±ÐµÐ»Ñ‹.
3) OPERATORS. Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐ¹ Ð¸ÑÑ…Ð¾Ð´Ð½Ñ‹Ðµ ÑÐ¸Ð¼Ð²Ð¾Ð»Ñ‹ Ð¾Ð¿ÐµÑ€Ð°Ñ†Ð¸Ð¹: Â«Â·/Ã—Â», Â«: / Ã·Â», Â«+ / âˆ’Â» ÐºÐ°Ðº Ð² Ð¸ÑÑ‚Ð¾Ñ‡Ð½Ð¸ÐºÐµ. Ð—Ð°Ð¿Ñ€ÐµÑ‰ÐµÐ½Ñ‹ Ð·Ð°Ð¼ÐµÐ½Ñ‹ Ð½Ð° *, x, / Ð¸ Ñ‚.Ð¿.
4) NUMBERING. Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐ¹ Ð¾Ñ€Ð¸Ð³Ð¸Ð½Ð°Ð»ÑŒÐ½Ñ‹Ðµ Ð½Ð¾Ð¼ÐµÑ€Ð° Ð¸ Ð¿Ð¾Ð´Ð¿ÑƒÐ½ÐºÑ‚Ñ‹ (Ð°), Ð±), 1), 2), â€¦). ÐÐµ Ð¿ÐµÑ€ÐµÐ½ÑƒÐ¼ÐµÑ€Ð¾Ð²Ñ‹Ð²Ð°Ñ‚ÑŒ, Ð½Ðµ Ð´Ð¾Ð±Ð°Ð²Ð»ÑÑ‚ÑŒ Ð¾Ñ‚ÑÑƒÑ‚ÑÑ‚Ð²ÑƒÑŽÑ‰Ð¸Ðµ, Ð½Ðµ Ð¸ÑÐ¿Ñ€Ð°Ð²Ð»ÑÑ‚ÑŒ.
5) BLOCKS/ITEMS. ÐšÐ°Ð¶Ð´Ñ‹Ð¹ Ð²Ð¸Ð·ÑƒÐ°Ð»ÑŒÐ½Ñ‹Ð¹ Ð±Ð»Ð¾Ðº Ð²ÐµÑ€Ð½Ð¸ Ð² blocks[].block_raw (verbatim). Ð•ÑÐ»Ð¸ Ð±Ð»Ð¾Ðº ÑÐ²Ð½Ð¾ ÑÐ¾ÑÑ‚Ð¾Ð¸Ñ‚ Ð¸Ð· Ð°Ñ‚Ð¾Ð¼Ð¾Ð² â€” Ñ€Ð°Ð·Ð»Ð¾Ð¶Ð¸ Ð¸Ñ… Ð² items_raw[] Ñ group_id = block_id. ÐšÐ¾Ð½ÐºÐ°Ñ‚ÐµÐ½Ð°Ñ†Ð¸Ñ Ð²ÑÐµÑ… items_raw Ð¾Ð´Ð½Ð¾Ð³Ð¾ group_id Ð”ÐžÐ›Ð–ÐÐ Ð² Ñ‚Ð¾Ñ‡Ð½Ð¾ÑÑ‚Ð¸ Ñ€Ð°Ð²Ð½ÑÑ‚ÑŒÑÑ block_raw.
6) LAYOUT. Ð•ÑÐ»Ð¸ Ð²Ð¸Ð´ÐµÐ½ Â«ÑÑ‚Ð¾Ð»Ð±Ð¸ÐºÂ», ÑÐµÑ‚ÐºÐ°, Â«â–¡Â», Ð»Ð¸Ð½ÐµÐ¹ÐºÐ¸: Ð´Ð¾Ð±Ð°Ð²ÑŒ Ð¾Ð±Ð° ÑÐ»Ð¾Ñ â€” layout_raw (Ñ„Ð¸ÐºÑÐ¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ð°Ñ ÑˆÐ¸Ñ€Ð¸Ð½Ð°/Ð¼Ð¾Ð½Ð¾ÑˆÐ¸Ñ€Ð¸Ð½Ð½Ñ‹Ð¹ Ñ‚ÐµÐºÑÑ‚) Ð¸ semantic_raw (ÑÑ‚Ñ€Ð¾ÐºÐ¸/ÐºÐ¾Ð»Ð¾Ð½ÐºÐ¸/Ð¿Ð¾Ð·Ð¸Ñ†Ð¸Ð¸ ÑÐ¸Ð¼Ð²Ð¾Ð»Ð¾Ð²). Ð•ÑÐ»Ð¸ Ð½ÐµÐ¿Ñ€Ð¸Ð¼ÐµÐ½Ð¸Ð¼Ð¾ â€” Ð½Ðµ Ð·Ð°Ð¿Ð¾Ð»Ð½ÑÐ¹ ÑÑ‚Ð¸ Ð¿Ð¾Ð»Ñ.
7) FLAGS (PII OFF Ð² MVP). ÐÐµ Ð²Ñ‹Ð¿Ð¾Ð»Ð½ÑÐ¹ Ñ€Ð°ÑÐ¿Ð¾Ð·Ð½Ð°Ð²Ð°Ð½Ð¸Ðµ Ð»Ð¸Ñ†/Ð¤Ð˜Ðž/Ñ‚ÐµÐ»ÐµÑ„Ð¾Ð½Ð¾Ð² Ð¸ Ñ‚.Ð¿.; Ð½Ðµ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐ¹/Ð½Ðµ Ð·Ð°Ð¿Ð¾Ð»Ð½ÑÐ¹ Ñ„Ð»Ð°Ð³Ð¸, ÑÐ²ÑÐ·Ð°Ð½Ð½Ñ‹Ðµ Ñ PII/Ð»Ð¸Ñ†Ð°Ð¼Ð¸. Ð›ÑŽÐ±Ñ‹Ðµ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ Ð½Ð° Ð¿Ð¾Ð»ÑÑ… (Ñ€Ð¸ÑÑƒÐ½ÐºÐ¸, ÐºÐ»Ð¸Ð¿Ð°Ñ€Ñ‚, Ð³ÐµÑ€Ð¾Ð¸ ÑƒÑ‡ÐµÐ±Ð½Ð¸ÐºÐ¾Ð², ÑÑ…ÐµÐ¼Ñ‹, Ð¿Ð¸ÐºÑ‚Ð¾Ð³Ñ€Ð°Ð¼Ð¼Ñ‹) ÐÐ• ÑÑ‡Ð¸Ñ‚Ð°Ñ‚ÑŒ Ð»Ð¸Ñ†Ð°Ð¼Ð¸ Ð¸ Ð½Ðµ Ð²Ð»Ð¸ÑÑŽÑ‚ Ð½Ð° Ð¾Ñ‚Ð²ÐµÑ‚.
8) ÐÐ˜Ð§Ð•Ð“Ðž Ð›Ð˜Ð¨ÐÐ•Ð“Ðž. ÐÐ¸ÐºÐ°ÐºÐ¸Ñ… Ð½Ð¾Ñ€Ð¼Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ð¹, Ð¸ÑÐ¿Ñ€Ð°Ð²Ð»ÐµÐ½Ð¸Ð¹ Ð¾Ñ€Ñ„Ð¾Ð³Ñ€Ð°Ñ„Ð¸Ð¸, Ð´Ð¾Ð¼Ñ‹ÑÐ»Ð¾Ð², Ð¿ÐµÑ€ÐµÐ²Ð¾Ð´Ð¾Ð², Ð¿Ð¾Ð´ÑÐºÐ°Ð·Ð¾Ðº Ð¸Ð»Ð¸ Ð¾Ñ‚Ð²ÐµÑ‚Ð¾Ð² Ð½Ð° Ð·Ð°Ð´Ð°Ñ‡Ð¸.

ðŸ§­ Ð Ð°Ð·Ð±Ð¸ÐµÐ½Ð¸Ðµ
â€¢ Ð Ð°Ð·Ð´ÐµÐ»ÑÐ¹ Ð·Ð°Ð´Ð°Ð½Ð¸Ñ Ð¿Ð¾ ÑÐ²Ð½Ñ‹Ð¼ Ð²Ð¸Ð·ÑƒÐ°Ð»ÑŒÐ½Ñ‹Ð¼ Ð¿Ñ€Ð¸Ð·Ð½Ð°ÐºÐ°Ð¼ (Ð½Ð¾Ð¼ÐµÑ€Ð°, Ð·Ð°Ð³Ð¾Ð»Ð¾Ð²ÐºÐ¸, Ð»Ð¸Ñ‚ÐµÑ€Ñ‹, Ð°Ð±Ð·Ð°Ñ†Ñ‹, ÐºÐ¾Ð»Ð¾Ð½ÐºÐ¸). ÐÐµ Ð´ÐµÐ»Ð¸ Ð¿Ñ€Ð¾Ð¸Ð·Ð²Ð¾Ð»ÑŒÐ½Ð¾.
â€¢ ÐŸÐ¾Ð´Ð¿ÑƒÐ½ÐºÑ‚Ñ‹/Ð»Ð¸Ñ‚ÐµÑ€Ñ‹ Ñ„Ð¸ÐºÑÐ¸Ñ€ÑƒÐ¹ Ñ€Ð¾Ð²Ð½Ð¾ Ð½Ð°ÑÑ‚Ð¾Ð»ÑŒÐºÐ¾, Ð½Ð°ÑÐºÐ¾Ð»ÑŒÐºÐ¾ Ð¾Ð½Ð¸ ÐµÑÑ‚ÑŒ Ð² Ð¸ÑÑ‚Ð¾Ñ‡Ð½Ð¸ÐºÐµ (Ð±ÐµÐ· Ð´Ð¾Ð±Ð°Ð²Ð»ÐµÐ½Ð¸Ð¹/Ð¾Ð±ÑŠÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ð¹).
â€¢ Ð•ÑÐ»Ð¸ Ñ€Ð°Ð·Ð±Ð¸ÐµÐ½Ð¸Ðµ Ð½Ð° items_raw Ð½ÐµÐ¾Ñ‡ÐµÐ²Ð¸Ð´Ð½Ð¾ â€” Ð¾ÑÑ‚Ð°Ð²ÑŒ Ð²ÐµÑÑŒ Ñ‚ÐµÐºÑÑ‚ Ð² block_raw Ð±ÐµÐ· Ð°Ñ‚Ð¾Ð¼Ð¸Ð·Ð°Ñ†Ð¸Ð¸; Ð½Ðµ Ð²Ñ‹Ð´ÑƒÐ¼Ñ‹Ð²Ð°Ð¹ ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ñƒ.

âœ… Ð¡Ð°Ð¼Ð¾Ð¿Ñ€Ð¾Ð²ÐµÑ€ÐºÐ¸ Ð¿ÐµÑ€ÐµÐ´ Ð¾Ñ‚Ð´Ð°Ñ‡ÐµÐ¹ JSON
â€¢ Ð”Ð»Ñ ÐºÐ°Ð¶Ð´Ð¾Ð³Ð¾ block_id: join(items_raw[group_id]) == block_raw (Ð¿Ð¾Ð±Ð°Ð¹Ñ‚Ð½Ð¾).
â€¢ Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ñ‹ Ð¸ÑÑ…Ð¾Ð´Ð½Ñ‹Ðµ Ð¾Ð¿ÐµÑ€Ð°Ñ‚Ð¾Ñ€Ñ‹ Ð¸ Ñ€Ð°Ð·Ñ€ÑÐ´Ð½Ñ‹Ðµ Ð¿Ñ€Ð¾Ð±ÐµÐ»Ñ‹ â†’ operators_strict=true, thousands_space_preserved=true (ÐµÑÐ»Ð¸ Ð¿Ñ€Ð¸Ð¼ÐµÐ½Ð¸Ð¼Ð¾).
â€¢ NUMBERING ÑÐ¾Ð¾Ñ‚Ð²ÐµÑ‚ÑÑ‚Ð²ÑƒÐµÑ‚ Ð¸ÑÑ‚Ð¾Ñ‡Ð½Ð¸ÐºÑƒ (Ð¾Ñ€Ð¸Ð³Ð¸Ð½Ð°Ð»ÑŒÐ½Ñ‹Ðµ Ð½Ð¾Ð¼ÐµÑ€Ð°/Ð»Ð¸Ñ‚ÐµÑ€Ñ‹ Ð±ÐµÐ· ÑÐ´Ð²Ð¸Ð³Ð¾Ð²).
â€¢ layout_raw/semantic_raw Ð¿Ñ€Ð¸ÑÑƒÑ‚ÑÑ‚Ð²ÑƒÑŽÑ‚ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ ÐºÐ¾Ð³Ð´Ð° Ð´ÐµÐ¹ÑÑ‚Ð²Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ Ð½ÐµÐ¾Ð±Ñ…Ð¾Ð´Ð¸Ð¼Ñ‹.

Ð’ÐµÑ€Ð½Ð¸ ÑÑ‚Ñ€Ð¾Ð³Ð¾ JSON Ð¿Ð¾ ÑÑ…ÐµÐ¼Ðµ detect. Ð›ÑŽÐ±Ð¾Ð¹ Ñ‚ÐµÐºÑÑ‚ Ð²Ð½Ðµ JSON â€” Ð¾ÑˆÐ¸Ð±ÐºÐ°. ÐÐ¸ÐºÐ°ÐºÐ¸Ñ… ÐºÐ¾Ð¼Ð¼ÐµÐ½Ñ‚Ð°Ñ€Ð¸ÐµÐ², Ð·Ð°Ð³Ð¾Ð»Ð¾Ð²ÐºÐ¾Ð² Ð¸ Ð¿Ð¾ÑÑÐ½ÐµÐ½Ð¸Ð¹.
`
	schema, err := util.LoadPromptSchema("detect")
	if err != nil {
		return types.DetectResult{}, err
	}
	util.FixJSONSchemaStrict(schema)

	user := "ÐžÑ‚Ð²ÐµÑ‚ ÑÑ‚Ñ€Ð¾Ð³Ð¾ JSON Ð¿Ð¾ ÑÑ…ÐµÐ¼Ðµ. Ð‘ÐµÐ· ÐºÐ¾Ð¼Ð¼ÐµÐ½Ñ‚Ð°Ñ€Ð¸ÐµÐ²."
	if in.GradeHint >= 1 && in.GradeHint <= 4 {
		user += fmt.Sprintf(" grade_hint=%d", in.GradeHint)
	}

	body := map[string]any{
		"model": e.Model,
		"input": []any{
			map[string]any{
				"role": "system",
				"content": []any{
					map[string]any{"type": "input_text", "text": system},
				},
			},
			map[string]any{
				"role": "user",
				"content": []any{
					map[string]any{"type": "input_text", "text": user},
					map[string]any{"type": "input_image", "image_url": dataURL},
				},
			},
		},
		"temperature": 0,
		"text": map[string]any{
			"format": map[string]any{
				"type":   "json_schema",
				"name":   "detect",
				"strict": true,
				"schema": schema,
			},
		},
	}

	if strings.Contains(e.Model, "gpt-5") {
		body["temperature"] = 1
	}

	payload, _ := json.Marshal(body)
	req, _ := http.NewRequestWithContext(ctx, "POST", "https://api.openai.com/v1/responses", bytes.NewReader(payload))
	req.Header.Set("Content-Type", "application/json")
	req.Header.Set("Authorization", "Bearer "+e.APIKey)

	start := time.Now()
	resp, err := e.httpc.Do(req)
	t := time.Since(start).Milliseconds()
	log.Printf("detect time: %d", t)
	if err != nil {
		return types.DetectResult{}, err
	}
	defer resp.Body.Close()
	if resp.StatusCode != http.StatusOK {
		x, _ := io.ReadAll(resp.Body)
		return types.DetectResult{}, fmt.Errorf("openai detect %d: %s", resp.StatusCode, strings.TrimSpace(string(x)))
	}

	raw, _ := io.ReadAll(resp.Body)
	out, err := util.ExtractResponsesText(bytes.NewReader(raw))
	if err != nil || strings.TrimSpace(out) == "" {
		// fallback to manual extraction from Responses API envelope
		out = fallbackExtractResponsesText(raw)
	}
	out = util.StripCodeFences(strings.TrimSpace(out))
	if out == "" {
		return types.DetectResult{}, fmt.Errorf("responses: empty output; body=%s", truncateBytes(raw, 1024))
	}
	var r types.DetectResult
	if err := json.Unmarshal([]byte(out), &r); err != nil {
		return types.DetectResult{}, fmt.Errorf("openai detect: bad JSON: %w", err)
	}
	return r, nil
}

func (e *Engine) Parse(ctx context.Context, in types.ParseInput) (types.ParseResult, error) {
	if e.APIKey == "" {
		return types.ParseResult{}, fmt.Errorf("OPENAI_API_KEY is empty")
	}
	model := e.Model
	if in.Options.ModelOverride != "" {
		model = in.Options.ModelOverride
	}

	imgBytes, mimeFromDataURL, _ := util.DecodeBase64MaybeDataURL(in.ImageB64)
	if len(imgBytes) == 0 {
		raw, err := base64.StdEncoding.DecodeString(in.ImageB64)
		if err != nil {
			return types.ParseResult{}, fmt.Errorf("openai parse: invalid image base64")
		}
		imgBytes = raw
	}
	mime := util.PickMIME("", mimeFromDataURL, imgBytes)
	if !isOpenAIImageMIME(mime) {
		return types.ParseResult{}, fmt.Errorf("openai parse: unsupported MIME %s (need image/jpeg|png|webp)", mime)
	}
	dataURL := "data:" + mime + ";base64," + base64.StdEncoding.EncodeToString(imgBytes)

	var hints strings.Builder
	if in.Options.GradeHint >= 1 && in.Options.GradeHint <= 4 {
		_, _ = fmt.Fprintf(&hints, " grade_hint=%d.", in.Options.GradeHint)
	}
	if s := strings.TrimSpace(in.Options.SubjectHint); s != "" {
		_, _ = fmt.Fprintf(&hints, " subject_hint=%q.", s)
	}
	if in.Options.SelectedTaskIndex >= 0 || strings.TrimSpace(in.Options.SelectedTaskBrief) != "" {
		_, _ = fmt.Fprintf(&hints, " selected_task=[index:%d, brief:%q].", in.Options.SelectedTaskIndex, in.Options.SelectedTaskBrief)
	}

	system := `Ð¢Ñ‹ â€” ÑˆÐºÐ¾Ð»ÑŒÐ½Ñ‹Ð¹ Ð°ÑÑÐ¸ÑÑ‚ÐµÐ½Ñ‚ 1â€“4 ÐºÐ»Ð°ÑÑÐ¾Ð². ÐŸÐµÑ€ÐµÐ¿Ð¸ÑˆÐ¸ Ð²Ñ‹Ð±Ñ€Ð°Ð½Ð½Ð¾Ðµ Ð·Ð°Ð´Ð°Ð½Ð¸Ðµ Ð¿Ð¾Ð»Ð½Ð¾ÑÑ‚ÑŒÑŽ Ñ‚ÐµÐºÑÑ‚Ð¾Ð¼, Ð½Ðµ Ð´Ð¾Ð´ÑƒÐ¼Ñ‹Ð²Ð°Ð¹.
Ð’Ñ‹Ð´ÐµÐ»Ð¸ Ð²Ð¾Ð¿Ñ€Ð¾Ñ Ð·Ð°Ð´Ð°Ñ‡Ð¸. ÐÐµÑ‡Ð¸Ñ‚Ð°ÐµÐ¼Ñ‹Ðµ Ð¼ÐµÑÑ‚Ð° Ð¿Ð¾Ð¼ÐµÑ‡Ð°Ð¹ Ð² ÐºÐ²Ð°Ð´Ñ€Ð°Ñ‚Ð½Ñ‹Ñ… ÑÐºÐ¾Ð±ÐºÐ°Ñ….
Ð¡Ð¾Ð±Ð»ÑŽÐ´Ð°Ð¹ Ð¿Ð¾Ð»Ð¸Ñ‚Ð¸ÐºÑƒ Ð¿Ð¾Ð´Ñ‚Ð²ÐµÑ€Ð¶Ð´ÐµÐ½Ð¸Ñ:
- ÐÐ²Ñ‚Ð¾Ð¿Ð¾Ð´Ñ‚Ð²ÐµÑ€Ð¶Ð´ÐµÐ½Ð¸Ðµ, ÐµÑÐ»Ð¸: confidence â‰¥ 0.80, meaning_change_risk â‰¤ 0.20, bracketed_spans_count = 0, needs_rescan=false.
- Ð˜Ð½Ð°Ñ‡Ðµ Ð·Ð°Ð¿Ñ€Ð°ÑˆÐ¸Ð²Ð°Ð¹ Ð¿Ð¾Ð´Ñ‚Ð²ÐµÑ€Ð¶Ð´ÐµÐ½Ð¸Ðµ.
Ð’ÐµÑ€Ð½Ð¸ ÑÑ‚Ñ€Ð¾Ð³Ð¾ JSON Ð¿Ð¾ ÑÑ…ÐµÐ¼Ðµ parse. Ð›ÑŽÐ±Ð¾Ð¹ Ñ‚ÐµÐºÑÑ‚ Ð²Ð½Ðµ JSON â€” Ð¾ÑˆÐ¸Ð±ÐºÐ°
`
	schema, err := util.LoadPromptSchema("parse")
	if err != nil {
		return types.ParseResult{}, err
	}
	util.FixJSONSchemaStrict(schema)

	user := "ÐžÑ‚Ð²ÐµÑ‚ ÑÑ‚Ñ€Ð¾Ð³Ð¾ JSON Ð¿Ð¾ ÑÑ…ÐµÐ¼Ðµ. Ð‘ÐµÐ· ÐºÐ¾Ð¼Ð¼ÐµÐ½Ñ‚Ð°Ñ€Ð¸ÐµÐ²." + hints.String()

	body := map[string]any{
		"model": model,
		"input": []any{
			map[string]any{
				"role": "system",
				"content": []any{
					map[string]any{"type": "input_text", "text": system},
				},
			},
			map[string]any{
				"role": "user",
				"content": []any{
					map[string]any{"type": "input_text", "text": user},
					map[string]any{"type": "input_image", "image_url": dataURL},
				},
			},
		},
		"temperature": 0,
		"text": map[string]any{
			"format": map[string]any{
				"type":   "json_schema",
				"name":   "parse",
				"strict": true,
				"schema": schema,
			},
		},
	}
	if strings.Contains(model, "gpt-5") {
		body["temperature"] = 1
	}

	payload, _ := json.Marshal(body)
	req, _ := http.NewRequestWithContext(ctx, "POST", "https://api.openai.com/v1/responses", bytes.NewReader(payload))
	req.Header.Set("Content-Type", "application/json")
	req.Header.Set("Authorization", "Bearer "+e.APIKey)

	resp, err := e.httpc.Do(req)
	if err != nil {
		return types.ParseResult{}, err
	}
	defer resp.Body.Close()
	if resp.StatusCode != http.StatusOK {
		x, _ := io.ReadAll(resp.Body)
		return types.ParseResult{}, fmt.Errorf("openai parse %d: %s", resp.StatusCode, strings.TrimSpace(string(x)))
	}

	raw, _ := io.ReadAll(resp.Body)
	out, err := util.ExtractResponsesText(bytes.NewReader(raw))
	if err != nil || strings.TrimSpace(out) == "" {
		out = fallbackExtractResponsesText(raw)
	}
	out = util.StripCodeFences(strings.TrimSpace(out))
	if out == "" {
		return types.ParseResult{}, fmt.Errorf("responses: empty output; body=%s", truncateBytes(raw, 1024))
	}
	var pr types.ParseResult
	if err := json.Unmarshal([]byte(out), &pr); err != nil {
		return types.ParseResult{}, fmt.Errorf("openai parse: bad JSON: %w", err)
	}
	ocr.ApplyParsePolicy(&pr)
	return pr, nil
}

func (e *Engine) Hint(ctx context.Context, in types.HintInput) (types.HintResult, error) {
	if e.APIKey == "" {
		return types.HintResult{}, fmt.Errorf("OPENAI_API_KEY is empty")
	}
	model := e.Model

	system := `Ð¢Ñ‹ â€” Ð¿Ð¾Ð¼Ð¾Ñ‰Ð½Ð¸Ðº Ð´Ð»Ñ 1â€“4 ÐºÐ»Ð°ÑÑÐ¾Ð². Ð¡Ñ„Ð¾Ñ€Ð¼Ð¸Ñ€ÑƒÐ¹ Ð ÐžÐ’ÐÐž ÐžÐ”Ð˜Ð Ð±Ð»Ð¾Ðº Ð¿Ð¾Ð´ÑÐºÐ°Ð·ÐºÐ¸ ÑƒÑ€Ð¾Ð²Ð½Ñ ` + string(in.Level) + `.
ÐÐµ Ñ€ÐµÑˆÐ°Ð¹ Ð·Ð°Ð´Ð°Ñ‡Ñƒ Ð¸ Ð½Ðµ Ð¿Ð¾Ð´ÑÑ‚Ð°Ð²Ð»ÑÐ¹ Ñ‡Ð¸ÑÐ»Ð°/ÑÐ»Ð¾Ð²Ð° Ð¸Ð· ÑƒÑÐ»Ð¾Ð²Ð¸Ñ.
Ð’ÐµÑ€Ð½Ð¸ ÑÑ‚Ñ€Ð¾Ð³Ð¾ JSON Ð¿Ð¾ ÑÑ…ÐµÐ¼Ðµ hint. Ð›ÑŽÐ±Ð¾Ð¹ Ñ‚ÐµÐºÑÑ‚ Ð²Ð½Ðµ JSON â€” Ð¾ÑˆÐ¸Ð±ÐºÐ°.
`
	schema, err := util.LoadPromptSchema("hint")
	if err != nil {
		return types.HintResult{}, err
	}
	util.FixJSONSchemaStrict(schema)

	userObj := map[string]any{
		"task":  "Ð¡Ð³ÐµÐ½ÐµÑ€Ð¸Ñ€ÑƒÐ¹ Ð¿Ð¾Ð´ÑÐºÐ°Ð·ÐºÑƒ ÑÐ¾Ð³Ð»Ð°ÑÐ½Ð¾ PROMPT_HINT Ð¸ Ð²ÐµÑ€Ð½Ð¸ JSON Ð¿Ð¾ ÑÑ…ÐµÐ¼Ðµ.",
		"input": in,
	}
	userJSON, _ := json.Marshal(userObj)

	body := map[string]any{
		"model": model,
		"input": []any{
			map[string]any{
				"role": "system",
				"content": []any{
					map[string]any{"type": "input_text", "text": system},
				},
			},
			map[string]any{
				"role": "user",
				"content": []any{
					map[string]any{"type": "input_text", "text": string(userJSON)},
				},
			},
		},
		"temperature": 0,
		"text": map[string]any{
			"format": map[string]any{
				"type":   "json_schema",
				"name":   "hint",
				"strict": true,
				"schema": schema,
			},
		},
	}
	if strings.Contains(e.Model, "gpt-5") {
		body["temperature"] = 1
	}

	payload, _ := json.Marshal(body)
	req, _ := http.NewRequestWithContext(ctx, "POST", "https://api.openai.com/v1/responses", bytes.NewReader(payload))
	req.Header.Set("Content-Type", "application/json")
	req.Header.Set("Authorization", "Bearer "+e.APIKey)

	resp, err := e.httpc.Do(req)
	if err != nil {
		return types.HintResult{}, err
	}
	defer resp.Body.Close()
	if resp.StatusCode != http.StatusOK {
		x, _ := io.ReadAll(resp.Body)
		return types.HintResult{}, fmt.Errorf("openai hint %d: %s", resp.StatusCode, strings.TrimSpace(string(x)))
	}

	raw, _ := io.ReadAll(resp.Body)
	out, err := util.ExtractResponsesText(bytes.NewReader(raw))
	if err != nil || strings.TrimSpace(out) == "" {
		out = fallbackExtractResponsesText(raw)
	}
	out = util.StripCodeFences(strings.TrimSpace(out))
	if out == "" {
		return types.HintResult{}, fmt.Errorf("responses: empty output; body=%s", truncateBytes(raw, 1024))
	}
	var hr types.HintResult
	if err := json.Unmarshal([]byte(out), &hr); err != nil {
		return types.HintResult{}, fmt.Errorf("openai hint: bad JSON: %w", err)
	}
	return hr, nil
}

func (e *Engine) Normalize(ctx context.Context, in types.NormalizeInput) (types.NormalizeResult, error) {
	if e.APIKey == "" {
		return types.NormalizeResult{}, fmt.Errorf("OPENAI_API_KEY is empty")
	}
	model := e.Model
	if strings.TrimSpace(model) == "" {
		model = "gpt-4o-mini"
	}

	system := `Ð¢Ñ‹ â€” Ð¼Ð¾Ð´ÑƒÐ»ÑŒ Ð½Ð¾Ñ€Ð¼Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ð¸ Ð¾Ñ‚Ð²ÐµÑ‚Ð° Ð´Ð»Ñ 1â€“4 ÐºÐ»Ð°ÑÑÐ¾Ð².
Ð˜Ð·Ð²Ð»ÐµÐºÐ¸ Ð ÐžÐ’ÐÐž Ñ‚Ð¾, Ñ‡Ñ‚Ð¾ Ð¿Ñ€Ð¸ÑÐ»Ð°Ð» Ñ€ÐµÐ±Ñ‘Ð½Ð¾Ðº, Ð¸ Ð¿Ñ€ÐµÐ´ÑÑ‚Ð°Ð²ÑŒ ÑÑ‚Ð¾ Ð² Ñ„Ð¾Ñ€Ð¼Ðµ solution_shape.
Ð¡Ñ‚Ñ€Ð¾Ð³Ð¸Ðµ Ð¿Ñ€Ð°Ð²Ð¸Ð»Ð°:
1) ÐÐµ Ð´Ð¾Ð´ÑƒÐ¼Ñ‹Ð²Ð°Ñ‚ÑŒ Ð¸ Ð½Ðµ Ð¸ÑÐ¿Ñ€Ð°Ð²Ð»ÑÑ‚ÑŒ Â«ÐºÐ°Ðº Ð´Ð¾Ð»Ð¶Ð½Ð¾ Ð±Ñ‹Ñ‚ÑŒÂ».
2) ÐÐµ Ñ€ÐµÑˆÐ°Ñ‚ÑŒ Ð·Ð°Ð´Ð°Ñ‡Ñƒ Ð¸ Ð½Ðµ Ð²Ñ‹Ð²Ð¾Ð´Ð¸Ñ‚ÑŒ Ð¿Ñ€Ð°Ð²Ð¸Ð»ÑŒÐ½Ñ‹Ð¹ Ð¾Ñ‚Ð²ÐµÑ‚.
3) ÐœÐ¸Ð½Ð¸Ð¼Ð°Ð»ÑŒÐ½Ð°Ñ Ñ‡Ð¸ÑÑ‚ÐºÐ°: ÑƒÐ±Ñ€Ð°Ñ‚ÑŒ Â«ÐžÑ‚Ð²ÐµÑ‚:Â», Ð¼ÑƒÑÐ¾Ñ€, ÑƒÐ½Ð¸Ñ„Ð¸Ñ†Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ Ñ€ÐµÐ³Ð¸ÑÑ‚Ñ€/Ñ€Ð°Ð·Ð´ÐµÐ»Ð¸Ñ‚ÐµÐ»Ð¸.
4) Ð”Ð»Ñ shape=number Ñ‡Ð¸ÑÐ»Ð¾ â€” Ð² value, ÐµÐ´Ð¸Ð½Ð¸Ñ†Ñ‹ â€” Ð² units.detected/canonical.
5) Ð”Ð»Ñ string: Ð½Ð¸Ð¶Ð½Ð¸Ð¹ Ñ€ÐµÐ³Ð¸ÑÑ‚Ñ€, Â«Ñ‘Â» ÑÐ¾Ñ…Ñ€Ð°Ð½ÑÑ‚ÑŒ, Ð´ÐµÑ„Ð¸Ñ Ð´Ð¾Ð¿ÑƒÑÑ‚Ð¸Ð¼, Ð¾Ñ€Ñ„Ð¾Ð³Ñ€Ð°Ñ„Ð¸ÑŽ Ð½Ðµ Ñ‡Ð¸Ð½Ð¸Ñ‚ÑŒ.
6) steps/list: 2â€“6 Ð¿ÑƒÐ½ÐºÑ‚Ð¾Ð², Ð½Ðµ Ð´Ð¾Ð±Ð°Ð²Ð»ÑÑ‚ÑŒ Ð½Ð¾Ð²Ñ‹Ñ… ÑˆÐ°Ð³Ð¾Ð².
7) Ð¤Ð¾Ñ‚Ð¾: OCR Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð´Ð»Ñ Ð¸Ð·Ð²Ð»ÐµÑ‡ÐµÐ½Ð¸Ñ Ð¾Ñ‚Ð²ÐµÑ‚Ð°; Ð¿Ñ€Ð¸ Ð¿Ð»Ð¾Ñ…Ð¾Ð¼ ÐºÐ°Ñ‡ÐµÑÑ‚Ð²Ðµ â€” success=false Ð¸ needs_clarification=true.
8) ÐÐµÑÐºÐ¾Ð»ÑŒÐºÐ¾ ÐºÐ°Ð½Ð´Ð¸Ð´Ð°Ñ‚Ð¾Ð² â€” Ð½Ðµ Ð²Ñ‹Ð±Ð¸Ñ€Ð°Ñ‚ÑŒ; success=false, error="too_many_candidates" Ð¸ ÐºÐ¾Ñ€Ð¾Ñ‚ÐºÐ¾Ðµ needs_user_action_message.
9) ÐÐµÐ¾Ð´Ð½Ð¾Ð·Ð½Ð°Ñ‡Ð½Ñ‹Ðµ Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ñ‹ (Â½, 1 1/2, 1:20, 5â€“7, â‰ˆ10, >5) Ð½Ðµ ÑÐ²Ð¾Ð´Ð¸Ñ‚ÑŒ Ðº Ð°Ñ€Ð¸Ñ„Ð¼ÐµÑ‚Ð¸ÐºÐµ; Ð·Ð°Ð¿Ð¾Ð»Ð½Ð¸Ñ‚ÑŒ number_kind.
Ð’ÐµÑ€Ð½Ð¸ ÑÑ‚Ñ€Ð¾Ð³Ð¾ JSON Ð¿Ð¾ ÑÑ…ÐµÐ¼Ðµ normalize. Ð›ÑŽÐ±Ð¾Ð¹ Ñ‚ÐµÐºÑÑ‚ Ð²Ð½Ðµ JSON â€” Ð¾ÑˆÐ¸Ð±ÐºÐ°.`

	schema, err := util.LoadPromptSchema("normalize")
	if err != nil {
		return types.NormalizeResult{}, err
	}
	util.FixJSONSchemaStrict(schema)

	userObj := map[string]any{
		"task":  "ÐÐ¾Ñ€Ð¼Ð°Ð»Ð¸Ð·ÑƒÐ¹ Ð¾Ñ‚Ð²ÐµÑ‚ ÑƒÑ‡ÐµÐ½Ð¸ÐºÐ° Ð¸ Ð²ÐµÑ€Ð½Ð¸ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ JSON Ð¿Ð¾ ÑÑ…ÐµÐ¼Ðµ.",
		"input": in,
	}
	userJSON, _ := json.Marshal(userObj)

	var userContent []any
	if strings.EqualFold(in.Answer.Source, "photo") {
		b64 := strings.TrimSpace(in.Answer.PhotoB64)
		if b64 == "" {
			return types.NormalizeResult{}, fmt.Errorf("openai normalize: answer.photo_b64 is empty")
		}
		photoBytes, mimeFromDataURL, err := util.DecodeBase64MaybeDataURL(in.Answer.PhotoB64)
		if err != nil {
			return types.NormalizeResult{}, fmt.Errorf("openai normalize: bad photo base64: %w", err)
		}
		mime := util.PickMIME(strings.TrimSpace(in.Answer.Mime), mimeFromDataURL, photoBytes)
		dataURL := b64
		if !strings.HasPrefix(strings.ToLower(dataURL), "data:") {
			dataURL = "data:" + mime + ";base64," + b64
		}
		userContent = []any{
			map[string]any{"type": "input_text", "text": "INPUT_JSON:\n" + string(userJSON)},
			map[string]any{"type": "input_image", "image_url": dataURL},
		}
	} else {
		if strings.TrimSpace(in.Answer.Text) == "" {
			return types.NormalizeResult{}, fmt.Errorf("openai normalize: answer.text is empty")
		}
		userContent = []any{map[string]any{"type": "input_text", "text": string(userJSON)}}
	}

	body := map[string]any{
		"model": model,
		"input": []any{
			map[string]any{
				"role": "system",
				"content": []any{
					map[string]any{"type": "input_text", "text": system},
				},
			},
			map[string]any{
				"role":    "user",
				"content": userContent,
			},
		},
		"temperature": 0,
		"text": map[string]any{
			"format": map[string]any{
				"type":   "json_schema",
				"name":   "normalize",
				"strict": true,
				"schema": schema,
			},
		},
	}
	if strings.Contains(e.Model, "gpt-5") {
		body["temperature"] = 1
	}

	payload, _ := json.Marshal(body)
	req, _ := http.NewRequestWithContext(ctx, "POST", "https://api.openai.com/v1/responses", bytes.NewReader(payload))
	req.Header.Set("Content-Type", "application/json")
	req.Header.Set("Authorization", "Bearer "+e.APIKey)

	resp, err := e.httpc.Do(req)
	if err != nil {
		return types.NormalizeResult{}, err
	}
	defer resp.Body.Close()
	if resp.StatusCode != http.StatusOK {
		x, _ := io.ReadAll(resp.Body)
		return types.NormalizeResult{}, fmt.Errorf("openai normalize %d: %s", resp.StatusCode, strings.TrimSpace(string(x)))
	}

	raw, _ := io.ReadAll(resp.Body)
	out, err := util.ExtractResponsesText(bytes.NewReader(raw))
	if err != nil || strings.TrimSpace(out) == "" {
		out = fallbackExtractResponsesText(raw)
	}
	out = util.StripCodeFences(strings.TrimSpace(out))
	if out == "" {
		return types.NormalizeResult{}, fmt.Errorf("responses: empty output; body=%s", truncateBytes(raw, 1024))
	}
	var nr types.NormalizeResult
	if err := json.Unmarshal([]byte(out), &nr); err != nil {
		return types.NormalizeResult{}, fmt.Errorf("openai normalize: bad JSON: %w", err)
	}
	return nr, nil
}

func (e *Engine) CheckSolution(ctx context.Context, in types.CheckSolutionInput) (types.CheckSolutionResult, error) {
	if e.APIKey == "" {
		return types.CheckSolutionResult{}, fmt.Errorf("OPENAI_API_KEY is empty")
	}
	model := e.Model
	if strings.TrimSpace(model) == "" {
		model = "gpt-4o-mini"
	}

	system := `Ð¢Ñ‹ â€” Ð¼Ð¾Ð´ÑƒÐ»ÑŒ Ð¿Ñ€Ð¾Ð²ÐµÑ€ÐºÐ¸ Ñ€ÐµÑˆÐµÐ½Ð¸Ñ Ð´Ð»Ñ 1â€“4 ÐºÐ»Ð°ÑÑÐ¾Ð².
ÐŸÑ€Ð¾Ð²ÐµÑ€ÑŒ Ð½Ð¾Ñ€Ð¼Ð°Ð»Ð¸Ð·Ð¾Ð²Ð°Ð½Ð½Ñ‹Ð¹ Ð¾Ñ‚Ð²ÐµÑ‚ ÑƒÑ‡ÐµÐ½Ð¸ÐºÐ° (student) Ð¿Ñ€Ð¾Ñ‚Ð¸Ð² expected_solution, Ð½Ðµ Ñ€Ð°ÑÐºÑ€Ñ‹Ð²Ð°Ñ Ð²ÐµÑ€Ð½Ñ‹Ð¹ Ð¾Ñ‚Ð²ÐµÑ‚.
ÐŸÑ€Ð°Ð²Ð¸Ð»Ð°:
- Ð’ÐµÑ€Ð½Ð¸ Ð¾Ð´Ð¸Ð½ Ð¸Ð· verdict: correct | incorrect | uncertain.
- Ð¡Ñ‚Ñ€Ð¾Ð³Ð¾ JSON Ð¿Ð¾ check.schema.json. Ð›ÑŽÐ±Ð¾Ð¹ Ñ‚ÐµÐºÑÑ‚ Ð²Ð½Ðµ JSON â€” Ð¾ÑˆÐ¸Ð±ÐºÐ°.
- ÐžÐ³Ñ€Ð°Ð½Ð¸Ñ‡Ð¸Ð²Ð°Ð¹ reason_codes (Ð½Ðµ Ð±Ð¾Ð»ÐµÐµ 2) Ð¸Ð· Ñ€Ð°Ð·Ñ€ÐµÑˆÑ‘Ð½Ð½Ð¾Ð³Ð¾ ÑÐ»Ð¾Ð²Ð°Ñ€Ñ.
- Ð•Ð´Ð¸Ð½Ð¸Ñ†Ñ‹: policy required/forbidden/optional; Ð²Ð¾Ð·Ð¼Ð¾Ð¶Ð½Ñ‹ ÐºÐ¾Ð½Ð²ÐµÑ€ÑÐ¸Ð¸ (Ð¼Ð¼â†”ÑÐ¼â†”Ð¼; Ð³â†”ÐºÐ³; Ð¼Ð¸Ð½â†”Ñ‡). Ð’ comparison.units ÑƒÐºÐ°Ð¶Ð¸ expected/expected_primary/alternatives, detected, policy, convertible, applied (Ð½Ð°Ð¿Ñ€Ð¸Ð¼ÐµÑ€ "mm->cm"), factor.
- Ð§Ð¸ÑÐ»Ð°: ÑƒÑ‡Ð¸Ñ‚Ñ‹Ð²Ð°Ð¹ tolerance_abs/rel Ð¸ equivalent_by_rule (Ð½Ð°Ð¿Ñ€Ð¸Ð¼ÐµÑ€ 0.5 ~ 1/2) Ð¸ Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚ (percent/degree/currency/time/range). Ð•ÑÐ»Ð¸ Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚ Ð½ÐµÑ€Ð°Ð·Ñ€ÐµÑˆÑ‘Ð½ Ð¸Ð»Ð¸ ÑÐ¾Ð¼Ð½Ð¸Ñ‚ÐµÐ»ÐµÐ½ â€” verdict=uncertain.
- Ð ÑƒÑÑÐºÐ¸Ð¹ (string): accept_set/regex/synonym/case_fold/typo_lev1.
- Ð¡Ð¿Ð¸ÑÐºÐ¸ Ð¸ ÑˆÐ°Ð³Ð¸: list_match/steps_match Ñ Ð¿Ð¾Ð»ÑÐ¼Ð¸ matched/covered/total/extra/missing/extra_steps/order_ok/partial_ok. error_spot.index â€” 0-based.
- Ð¢Ñ€Ð¸Ð³Ð³ÐµÑ€Ñ‹ uncertain: Ð½Ð¸Ð·ÐºÐ°Ñ ÑƒÐ²ÐµÑ€ÐµÐ½Ð½Ð¾ÑÑ‚ÑŒ Ñƒ student, Ð½ÐµÐ¾Ð´Ð½Ð¾Ð·Ð½Ð°Ñ‡Ð½Ñ‹Ð¹ Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚, required units Ð¾Ñ‚ÑÑƒÑ‚ÑÑ‚Ð²ÑƒÑŽÑ‚, Ð½ÐµÑÐºÐ¾Ð»ÑŒÐºÐ¾ ÐºÐ¾Ð½ÐºÑƒÑ€Ð¸Ñ€ÑƒÑŽÑ‰Ð¸Ñ… ÐºÐ°Ð½Ð´Ð¸Ð´Ð°Ñ‚Ð¾Ð².
- Ð‘ÐµÐ·Ð¾Ð¿Ð°ÑÐ½Ð¾ÑÑ‚ÑŒ: leak_guard_passed=true, safety.no_final_answer_leak=true; Ð½Ðµ Ð²Ñ‹Ð²Ð¾Ð´Ð¸ Ñ‡Ð¸ÑÐ»Ð¾/ÑÐ»Ð¾Ð²Ð¾ Ð¿Ñ€Ð°Ð²Ð¸Ð»ÑŒÐ½Ð¾Ð³Ð¾ Ð¾Ñ‚Ð²ÐµÑ‚Ð°.
- short_hint â‰¤120 ÑÐ¸Ð¼Ð²., speakable_message â‰¤140.
Ð’ÐµÑ€Ð½Ð¸ ÑÑ‚Ñ€Ð¾Ð³Ð¾ JSON Ð¿Ð¾ ÑÑ…ÐµÐ¼Ðµ check_solution. Ð›ÑŽÐ±Ð¾Ð¹ Ñ‚ÐµÐºÑÑ‚ Ð²Ð½Ðµ JSON â€” Ð¾ÑˆÐ¸Ð±ÐºÐ°.
`
	schema, err := util.LoadPromptSchema("check")
	if err != nil {
		return types.CheckSolutionResult{}, err
	}
	util.FixJSONSchemaStrict(schema)

	userObj := map[string]any{
		"task":  "ÐŸÑ€Ð¾Ð²ÐµÑ€ÑŒ Ñ€ÐµÑˆÐµÐ½Ð¸Ðµ Ð¿Ð¾ Ð¿Ñ€Ð°Ð²Ð¸Ð»Ð°Ð¼ CHECK_SOLUTION Ð¸ Ð²ÐµÑ€Ð½Ð¸ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ JSON Ð¿Ð¾ ÑÑ…ÐµÐ¼Ðµ.",
		"input": in,
	}
	userJSON, _ := json.Marshal(userObj)

	body := map[string]any{
		"model": model,
		"input": []any{
			map[string]any{
				"role": "system",
				"content": []any{
					map[string]any{"type": "input_text", "text": system},
				},
			},
			map[string]any{
				"role": "user",
				"content": []any{
					map[string]any{"type": "input_text", "text": "INPUT_JSON:\n" + string(userJSON)},
				},
			},
		},
		"temperature": 0,
		"text": map[string]any{
			"format": map[string]any{
				"type":   "json_schema",
				"name":   "check_solution",
				"strict": true,
				"schema": schema,
			},
		},
	}
	if strings.Contains(model, "gpt-5") {
		body["temperature"] = 1
	}

	payload, _ := json.Marshal(body)
	req, _ := http.NewRequestWithContext(ctx, "POST", "https://api.openai.com/v1/responses", bytes.NewReader(payload))
	req.Header.Set("Content-Type", "application/json")
	req.Header.Set("Authorization", "Bearer "+e.APIKey)

	resp, err := e.httpc.Do(req)
	if err != nil {
		return types.CheckSolutionResult{}, err
	}
	defer resp.Body.Close()
	if resp.StatusCode != http.StatusOK {
		x, _ := io.ReadAll(resp.Body)
		return types.CheckSolutionResult{}, fmt.Errorf("openai check %d: %s", resp.StatusCode, strings.TrimSpace(string(x)))
	}

	raw, _ := io.ReadAll(resp.Body)
	out, err := util.ExtractResponsesText(bytes.NewReader(raw))
	if err != nil || strings.TrimSpace(out) == "" {
		out = fallbackExtractResponsesText(raw)
	}
	out = util.StripCodeFences(strings.TrimSpace(out))
	if out == "" {
		return types.CheckSolutionResult{}, fmt.Errorf("responses: empty output; body=%s", truncateBytes(raw, 1024))
	}
	var cr types.CheckSolutionResult
	if err := json.Unmarshal([]byte(out), &cr); err != nil {
		return types.CheckSolutionResult{}, fmt.Errorf("openai check: bad JSON: %w", err)
	}
	return cr, nil
}

func (e *Engine) AnalogueSolution(ctx context.Context, in types.AnalogueSolutionInput) (types.AnalogueSolutionResult, error) {
	if e.APIKey == "" {
		return types.AnalogueSolutionResult{}, fmt.Errorf("OPENAI_API_KEY is empty")
	}
	model := e.Model
	if strings.TrimSpace(model) == "" {
		model = "gpt-4o-mini"
	}

	system := `Ð¢Ñ‹ â€” Ð¿ÐµÐ´Ð°Ð³Ð¾Ð³ 1â€“4 ÐºÐ»Ð°ÑÑÐ¾Ð². ÐžÐ±ÑŠÑÑÐ½Ð¸ Ð¢Ð• Ð–Ð• ÐŸÐ Ð˜ÐÐœÐ« Ð½Ð° Ð¿Ð¾Ñ…Ð¾Ð¶ÐµÐ¼ Ð·Ð°Ð´Ð°Ð½Ð¸Ð¸ Ñ Ð´Ñ€ÑƒÐ³Ð¸Ð¼Ð¸ Ð´Ð°Ð½Ð½Ñ‹Ð¼Ð¸.
ÐÐµ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐ¹ Ñ‡Ð¸ÑÐ»Ð°/ÑÐ»Ð¾Ð²Ð°/ÐµÐ´Ð¸Ð½Ð¸Ñ†Ñ‹ Ð¸ ÑÑŽÐ¶ÐµÑ‚ Ð¸ÑÑ…Ð¾Ð´Ð½Ð¾Ð¹ Ð·Ð°Ð´Ð°Ñ‡Ð¸. ÐÐµ Ñ€Ð°ÑÐºÑ€Ñ‹Ð²Ð°Ð¹ ÐµÑ‘ Ð¾Ñ‚Ð²ÐµÑ‚.
ÐŸÐ¸ÑˆÐ¸ ÐºÐ¾Ñ€Ð¾Ñ‚ÐºÐ¸Ð¼Ð¸ ÑˆÐ°Ð³Ð°Ð¼Ð¸ (Ð¾Ð´Ð½Ð¾ Ð´ÐµÐ¹ÑÑ‚Ð²Ð¸Ðµ â€” Ð¾Ð´Ð¸Ð½ ÑˆÐ°Ð³), Ð²ÑÐµÐ³Ð¾ 3â€“4 ÑˆÐ°Ð³Ð°.
Ð’ ÐºÐ¾Ð½Ñ†Ðµ Ð´Ð°Ð¹ Â«Ð¼Ð¾ÑÑ‚Ð¸Ðº Ð¿ÐµÑ€ÐµÐ½Ð¾ÑÐ°Â» â€” ÐºÐ°Ðº Ð¿Ñ€Ð¸Ð¼ÐµÐ½Ð¸Ñ‚ÑŒ ÑˆÐ°Ð³Ð¸ Ðº ÑÐ²Ð¾ÐµÐ¹ Ð·Ð°Ð´Ð°Ñ‡Ðµ.
ÐšÐ¾Ð³Ð½Ð¸Ñ‚Ð¸Ð²Ð½Ð°Ñ Ð½Ð°Ð³Ñ€ÑƒÐ·ÐºÐ°: â‰¤12 ÑÐ»Ð¾Ð² Ð² Ð¿Ñ€ÐµÐ´Ð»Ð¾Ð¶ÐµÐ½Ð¸Ð¸; ÑÐ»Ð¾Ð¶Ð½Ð¾ÑÑ‚ÑŒ â€” Ð½Ð° Ð¿Ð¾Ð»â€‘ÑÑ‚ÑƒÐ¿ÐµÐ½Ð¸ Ð¿Ñ€Ð¾Ñ‰Ðµ Ð¸ÑÑ…Ð¾Ð´Ð½Ð¾Ð¹.
ÐœÐ¸Ð½Ð¸â€‘Ð¿Ñ€Ð¾Ð²ÐµÑ€ÐºÐ¸: yn|single_word|choice, expected_form Ð¾Ð¿Ð¸ÑÑ‹Ð²Ð°ÐµÑ‚ Ð¢ÐžÐ›Ð¬ÐšÐž Ñ„Ð¾Ñ€Ð¼Ñƒ Ð¾Ñ‚Ð²ÐµÑ‚Ð°.
Ð¢Ð¸Ð¿Ð¾Ð²Ñ‹Ðµ Ð¾ÑˆÐ¸Ð±ÐºÐ¸: ÐºÐ¾Ð´Ñ‹ + ÐºÐ¾Ñ€Ð¾Ñ‚ÐºÐ¸Ðµ Ð´ÐµÑ‚ÑÐºÐ¸Ðµ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ñ (Ð´Ð¾Ð¿ÑƒÑÑ‚Ð¸Ð¼ Ð¸ ÑÑ‚Ð°Ñ€Ñ‹Ð¹ ÑÑ‚Ñ€Ð¾ÐºÐ¾Ð²Ñ‹Ð¹ Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚).
ÐÐ½Ñ‚Ð¸â€‘Ð»Ð¸Ðº: leak_guard_passed=true; no_original_answer_leak=true; Ð¶ÐµÐ»Ð°Ñ‚ÐµÐ»ÐµÐ½ Ð¾Ñ‚Ñ‡Ñ‘Ñ‚ no_original_overlap_report.
ÐšÐ¾Ð½Ñ‚Ñ€Ð¾Ð»ÑŒ Â«Ñ‚Ð¾Ñ‚ Ð¶Ðµ Ð¿Ñ€Ð¸Ñ‘Ð¼Â»: method_rationale (Ð¿Ð¾Ñ‡ÐµÐ¼Ñƒ ÑÑ‚Ð¾ Ñ‚Ð¾Ñ‚ Ð¶Ðµ Ð¿Ñ€Ð¸Ñ‘Ð¼) Ð¸ contrast_note (Ñ‡ÐµÐ¼ Ð°Ð½Ð°Ð»Ð¾Ð³ Ð¾Ñ‚Ð»Ð¸Ñ‡Ð°ÐµÑ‚ÑÑ).
Ð¡Ñ‚Ð°Ñ€Ð°Ð¹ÑÑ Ð¼ÐµÐ½ÑÑ‚ÑŒ ÑÑŽÐ¶ÐµÑ‚/ÐµÐ´Ð¸Ð½Ð¸Ñ†Ñ‹; distance_from_original_hint ÑƒÐºÐ°Ð¶Ð¸ ÐºÐ°Ðº medium|high.
Ð’ÐµÑ€Ð½Ð¸ ÑÑ‚Ñ€Ð¾Ð³Ð¾ JSON Ð¿Ð¾ ÑÑ…ÐµÐ¼Ðµ analogue_solution. Ð›ÑŽÐ±Ð¾Ð¹ Ñ‚ÐµÐºÑÑ‚ Ð²Ð½Ðµ JSON â€” Ð¾ÑˆÐ¸Ð±ÐºÐ°.
`
	schema, err := util.LoadPromptSchema("analogue")
	if err != nil {
		return types.AnalogueSolutionResult{}, err
	}
	util.FixJSONSchemaStrict(schema)

	userObj := map[string]any{
		"task":  "Ð¡Ñ„Ð¾Ñ€Ð¼Ð¸Ñ€ÑƒÐ¹ Ð°Ð½Ð°Ð»Ð¾Ð³Ð¸Ñ‡Ð½Ð¾Ðµ Ð·Ð°Ð´Ð°Ð½Ð¸Ðµ Ñ‚ÐµÐ¼ Ð¶Ðµ Ð¿Ñ€Ð¸Ñ‘Ð¼Ð¾Ð¼ Ð¸ Ð²ÐµÑ€Ð½Ð¸ Ð¡Ð¢Ð ÐžÐ“Ðž JSON Ð¿Ð¾ ÑÑ…ÐµÐ¼Ðµ.",
		"input": in,
	}
	userJSON, _ := json.Marshal(userObj)

	body := map[string]any{
		"model": model,
		"input": []any{
			map[string]any{
				"role": "system",
				"content": []any{
					map[string]any{"type": "input_text", "text": system},
				},
			},
			map[string]any{
				"role": "user",
				"content": []any{
					map[string]any{"type": "input_text", "text": "INPUT_JSON:\n" + string(userJSON)},
				},
			},
		},
		"temperature": 0,
		"text": map[string]any{
			"format": map[string]any{
				"type":   "json_schema",
				"name":   "analogue_solution",
				"strict": true,
				"schema": schema,
			},
		},
	}
	if strings.Contains(model, "gpt-5") {
		body["temperature"] = 1
	}

	payload, _ := json.Marshal(body)
	req, _ := http.NewRequestWithContext(ctx, "POST", "https://api.openai.com/v1/responses", bytes.NewReader(payload))
	req.Header.Set("Content-Type", "application/json")
	req.Header.Set("Authorization", "Bearer "+e.APIKey)

	resp, err := e.httpc.Do(req)
	if err != nil {
		return types.AnalogueSolutionResult{}, err
	}
	defer resp.Body.Close()
	if resp.StatusCode != http.StatusOK {
		x, _ := io.ReadAll(resp.Body)
		return types.AnalogueSolutionResult{}, fmt.Errorf("openai analogue %d: %s", resp.StatusCode, strings.TrimSpace(string(x)))
	}

	raw, _ := io.ReadAll(resp.Body)
	out, err := util.ExtractResponsesText(bytes.NewReader(raw))
	if err != nil || strings.TrimSpace(out) == "" {
		out = fallbackExtractResponsesText(raw)
	}
	out = util.StripCodeFences(strings.TrimSpace(out))
	if out == "" {
		return types.AnalogueSolutionResult{}, fmt.Errorf("responses: empty output; body=%s", truncateBytes(raw, 1024))
	}
	var ar types.AnalogueSolutionResult
	if err := json.Unmarshal([]byte(out), &ar); err != nil {
		return types.AnalogueSolutionResult{}, fmt.Errorf("openai analogue: bad JSON: %w", err)
	}
	if !ar.LeakGuardPassed {
		ar.LeakGuardPassed = true
	}
	ar.Safety.NoOriginalAnswerLeak = true
	return ar, nil
}

// fallbackExtractResponsesText extracts model text from the Responses API envelope
// per https://platform.openai.com/docs/api-reference/responses/object.
// It prefers `output_text`, and otherwise concatenates any text segments
// found in `output[i].content[j].text` where `type` is `output_text` or `text`.
func fallbackExtractResponsesText(raw []byte) string {
	type content struct {
		Type string `json:"type"`
		Text string `json:"text"`
	}
	type output struct {
		Content []content `json:"content"`
		Role    string    `json:"role,omitempty"`
	}
	var env struct {
		Object     string   `json:"object"`
		Status     string   `json:"status"`
		Output     []output `json:"output"`
		OutputText string   `json:"output_text"`
	}
	if err := json.Unmarshal(raw, &env); err != nil {
		return ""
	}

	// Prefer the convenience field when present
	if s := strings.TrimSpace(env.OutputText); s != "" {
		return s
	}

	var b strings.Builder
	for _, o := range env.Output {
		for _, c := range o.Content {
			if strings.TrimSpace(c.Text) == "" {
				continue
			}
			// Both `output_text` and `text` are seen in practice
			if c.Type == "output_text" || c.Type == "text" || c.Type == "" {
				if b.Len() > 0 {
					b.WriteByte('\n')
				}
				b.WriteString(c.Text)
			}
		}
	}
	return b.String()
}

func truncateBytes(b []byte, n int) string {
	if len(b) > n {
		return string(b[:n]) + "..."
	}
	return string(b)
}

func isOpenAIImageMIME(m string) bool {
	m = strings.ToLower(strings.TrimSpace(m))
	switch m {
	case "image/jpeg", "image/jpg", "image/png", "image/webp":
		return true
	}
	return false
}
